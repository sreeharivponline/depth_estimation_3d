{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6796d5c-0430-46ee-8b3a-8c96982a37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sreeh\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7b782-0526-496c-bce4-785da1747194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import GLPNImageProcessor, GLPNForDepthEstimation\n",
    "\n",
    "\n",
    "feature_extractor = GLPNImageProcessor.from_pretrained(\"vinvino02/glpn-nyu\")\n",
    "model = GLPNForDepthEstimation.from_pretrained(\"vinvino02/glpn-nyu\")\n",
    "\n",
    "# load and resize the input image\n",
    "image = Image.open(r\"C:\\Users\\sreeh\\Downloads\\white-rabbit-animal-cartoon-white-background\\0zma_wuit_210811.jpg\")\n",
    "new_height = 480 if image.height > 480 else image.height\n",
    "new_height -= (new_height % 32)\n",
    "new_width = int(new_height * image.width / image.height)\n",
    "diff = new_width % 32\n",
    "new_width = new_width - diff if diff < 16 else new_width + 32 - diff\n",
    "new_size = (new_width, new_height)\n",
    "image = image.resize(new_size)\n",
    "\n",
    "# prepare image for the model\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# get the prediction from the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predicted_depth = outputs.predicted_depth\n",
    "\n",
    "# remove borders\n",
    "pad = 16\n",
    "output = predicted_depth.squeeze().cpu().numpy() * 1000.0\n",
    "output = output[pad:-pad, pad:-pad]\n",
    "image = image.crop((pad, pad, image.width - pad, image.height - pad))\n",
    "\n",
    "# visualize the prediction\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(image)\n",
    "ax[0].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "ax[1].imshow(output, cmap='plasma')\n",
    "ax[1].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "plt.tight_layout()\n",
    "plt.pause(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eea5f1f-5c17-4937-b485-582f0b9341c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'open3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mo3d\u001b[39;00m\n\u001b[0;32m      5\u001b[0m width, height \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m      7\u001b[0m depth_image \u001b[38;5;241m=\u001b[39m (output \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(output))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'open3d'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "width, height = image.size\n",
    "\n",
    "depth_image = (output * 255 / np.max(output)).astype('uint8')\n",
    "image = np.array(image)\n",
    "\n",
    "# create rgbd image\n",
    "depth_o3d = o3d.geometry.Image(depth_image)\n",
    "image_o3d = o3d.geometry.Image(image)\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(image_o3d, depth_o3d, convert_rgb_to_intensity=False)\n",
    "\n",
    "# camera settings\n",
    "camera_intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "camera_intrinsic.set_intrinsics(width, height, 500, 500, width/2, height/2)\n",
    "\n",
    "# create point cloud\n",
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, camera_intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a006c8f0-9ee6-48a4-8710-8db79f6fa855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eff4171-2be6-43b5-88e8-66f9580ba264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "source": [
    "cl, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=20.0)\n",
    "pcd = pcd.select_by_index(ind)\n",
    "\n",
    "# estimate normals\n",
    "pcd.estimate_normals()\n",
    "pcd.orient_normals_to_align_with_direction()\n",
    "\n",
    "# surface reconstruction\n",
    "mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=10, n_threads=1)[0]\n",
    "\n",
    "# rotate the mesh\n",
    "rotation = mesh.get_rotation_matrix_from_xyz((np.pi, 0, 0))\n",
    "mesh.rotate(rotation, center=(0, 0, 0))\n",
    "\n",
    "# save the mesh\n",
    "o3d.io.write_triangle_mesh(f'./mesh.obj', mesh)\n",
    "\n",
    "# visualize the mesh\n",
    "o3d.visualization.draw_geometries([mesh], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16effd1-43cc-4722-8a20-4f4904dbf7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
